##
# 一，[Embedding层](https://pytorch.org/docs/master/generated/torch.nn.Embedding.html?highlight=nn%20embedding#torch.nn.Embedding)

## 1.原理

随机初始化权重，然后根据索引获取代表某个索引的[1,X]向量

## 2.举例

```python
torch.Size([2, 4, 3])import torch
import torch.nn as nn

embedding = nn.Embedding(10, 3)  # 模拟10个字，每个字3维嵌入
input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])  模拟(bs,seq_len)[2,4]
output = embedding(input)

print(output.shape)
# torch.Size([2, 4, 3])
print(embedding.state_dict())  # 查看嵌入矩阵
'''
OrderedDict([('weight', tensor([
        [-3.3578e-01,  1.4503e+00,  5.4208e-01],
        [-3.1364e-01,  5.7434e-02,  6.0398e-01],
        [ 1.0265e-01, -1.3820e-03,  1.4946e+00],
        [ 4.0557e-02,  1.5681e+00,  6.0269e-01],
        [-2.8694e-01,  8.7456e-01, -1.3550e+00],
        [ 1.7686e-01,  5.5942e-01, -4.4190e-01],
        [ 3.3389e-01,  5.8763e-01, -3.4267e-02],
        [-2.1420e+00, -3.3126e-01,  1.0392e+00],
        [-7.3949e-01, -2.8852e-01, -6.7527e-02],
        [ 2.5636e-01, -1.0506e+00, -1.2807e+00]]))])
'''
```

## 3.应用

很广，我知道的就有NLP方面：从NNLM的look up table到word2vec的词向量到后面各种预训练模型的词向量

推荐搜索方面：将人或者物品标签嵌入成embedding的方式进行训练(learn to rank的训练)

## 4.优缺点

优点：

1. 将离散的特征值变成了连续的向量，可以送进网络进行训练

缺点：

1. 需要人为选定嵌入维度

# 二，[Dropout](https://pytorch.org/docs/master/generated/torch.nn.Dropout.html?highlight=nn%20dropout#torch.nn.Dropout)

## 1.原理

在训练时通过P的概率随机丢弃神经元，然后在保留的神经元权重都乘上$\frac{1}{1-p}$来扩大其影响

## 2.举例

```python
import torch
import torch.nn as nn

m = nn.Dropout(p=0.2)
input = torch.randn(1, 10)
output = m(input)

print(output)
# tensor([[ 1.6276,  0.0000,  0.2728,  0.0000, -0.4678,  0.0126,  0.8171, -0.7237,
#          -0.0000, -0.5285]])
```

## 3.应用

常用在全连接，卷积层后减少过拟合

## 4.优缺点

优点：

1. 能起到降低过拟合的作用

缺点：

1. 丢弃概率P的选值需要凭经验定
2. 训练时间会加长
3. 通常效果没有BN好

# 三，[BN、LN层](https://pytorch.org/docs/master/generated/torch.nn.BatchNorm1d.html?highlight=batch#torch.nn.BatchNorm1d)

## 1.原理

通过在新的网络输入前对输入数据进行标准处理

## 2.举例

$y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta$

## 3.应用

在文本的标准化中，常用LN对输入文本做标准化；在图像的标准化中，常用BN对输入文本做标准化处理

## 4.优缺点

优点：

1. 可以调整训练过程中数据的分布，加速收敛
2. 能缓解梯度饱和/消失时权重变化
