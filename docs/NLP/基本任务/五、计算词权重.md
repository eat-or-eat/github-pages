##
# 一，为什么要计算词权重

1. 词权重可以在各种任务（基于tfidf的文本分类等简单使用）
2. 也可以在其他算法中组合使用（多种词权重计算方式和作为文档相似度的判断）

# 二，怎么获取

## 1.分词方法

首先要分词，分词的方法有正向最大匹配，反向最大匹配，双向最大匹配法等方法，但都需要一个词表来做切分

## 2.优缺点

优点：

1. 简单实现，可以掉包

缺点：

1. 依赖词表，如果有新的词没出现过就分不出来
2. 错别字对分词结果影响很大

## 3.缺点的处理方式

### 1.对于没见过的词：新词发现

$新词可能值=互信息*左右熵$

$互信息（内部稳定）：\frac{1}nlog\frac{P(W)}{P(c1)P(c2)\cdot\cdot\cdot P(cn)},P(W)为词概率、P(cn)为字概率、n为字个数$

$左右熵（外部多变）：max(-\sum P_llogP_l,-\sum P_rlogP_r)$

### 2.对于本身文本错的词：文本纠错

通过语言模型对文本的成句概率进行判断，然后通过同音字或其他字表进行替换，如果超过了某个阈值则进行替换

# 三，怎么计算

## TFIDF

$tfidf = tf * idf$

$tf:\frac{某词在某类别中出现的次数}{该类别词总数} idf:\frac{语料库总文档数}{包含该词的文档数+1}$

## 优缺点

优点：

1. 计算简单，可通过统计解释
2. 可以和其他算法组合做词权重

缺点：

1. 计算效果好前提是分词能较好地分出相应的词
2. 数据分布不均衡会影响重要词的权重,比如科技类里面如果没出现过手机电脑，那手机电脑依然不会有较高的词权重甚至没有这个分数;或者文本很长重要词只出现一两次
3. 只有一片文档无法计算IDF也就不能计算IFIDF
4. 相对于神经网络，无法完成复杂任务，比如机器翻译，实体抽取等

## BM25

$Score(Q,d)=\sum^n_iW_iR(q_i,d)$