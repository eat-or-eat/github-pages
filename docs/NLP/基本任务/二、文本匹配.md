##
# 一，使用场景

> 从文本的长短进行分类的话

1. 短对短:简单知识库问答，机器指令识别，句子相似度匹配等
2. 短对长:文章检索，详细知识库问答等
3. 长对长:文章相似度匹配等

# 二，基本流程

1. 收集数据:最好是公司有数据，不然找到的数据可能跟应用场景差很多，实在不行就直接用预训练模型输出标准问(答)的向量进行表示型的匹配
2. 模型训练:多种模型根据有无GPU，需要的指标类型，指标最低分数等决定如何选取
3. 预测:根据是否通过网络调用判断是否需要封装成web接口

# 三，可选模型

## 1.编辑距离

### 方法

编辑距离选出来的值是一个0-N的数字，相似度匹配需要0-1表示是否相似，通过后面公式对器进行转换:$similarity=1-\frac{ED_{AB}}{max(L_A,L_B)}$

### 优缺点：

优点:

1. 可解释性强，因为编辑距离可以人工判断是那些字符的影响
2. 不用训练,可以跨语种，不同语种之间不用再单独训练

缺点:

1. 无法获取词意，句意，时序，语序等语言特征
2. 停用词，无关词对结果影响大
3. 文本长度影响识别速度O(MN)

## 2.Jaccard相似度

### 方法

$J(A,B)=\frac{A \cap B}{A \cup B}=\frac{文本中元素的交集}{文本中元素的并集}$

### 优缺点:

优点:

1. 可解释性强
2. 同样可以跨语种

缺点:

1. 无法获取词意，句意，时序，语序等语言特征
2. 不一样意思的文本可能获得满分:我喜欢吃米饭，他喜欢吃面条 != 我喜欢吃面条，他喜欢吃米饭
3. 文本长度影响识别速度

## 3.词权重-TFIDF与BM25

### 方法

通过词权重算法获取某一类别词的权重分值，然后进行匹配获取最高相似度文本

### 优缺点

优点:

1. 可解释性强，能看到是哪些词的权重高
2. 快,可以提前算出来，使用时直接查找相关词权重

缺点:

1. 无法获取词意，句意，时序，语序等语言特征
2. 需要一定的统计样本

## 4.SentenceBert[1908.10084.pdf (arxiv.org)](https://arxiv.org/pdf/1908.10084.pdf)

### 方法

将句子通过bert共享权重，表示然后三种训练方式:分类训练，MSE训练，triplet训练

### 优缺点

优点:

1. 训练好的模型可以提前对需要对比的句子向量化

缺点:

1. 预训练模型预测仍然相对比较慢

# 四，工程问题

如何快速的在一大堆向量中找到需要的向量:Annoy（ Approximate Nearest Neighbors  Oh Yeah ）

# 五，经验总结

先设计或写好联调接口，然后根据数据和场景选取模型并调优
